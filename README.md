<h1 align="center"> Rock-Paper-Scissors Classifier </h1>
<p align="center">
    <img src="images/rps.png" width="600">
</p>

## Overview
This project is an image classification application using Tensorflow and Keras. This dataset contains images of hand gestures from the game Rock-Paper-Scissors. In this project I created a machine learning model using the Convolution Neural Network from Tensorflow to classify Rock-Paper-Scissors data.

## Dataset
The data set for this project was obtained from GoogleAPIs, in [this](https://www.kaggle.com/cdawn1/messy-vs-clean-room) and [this](https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps-test-set.zip). You can also get it from [Kaggle](https://www.kaggle.com/sanikamal/rock-paper-scissors-dataset)
Rock Paper Scissors contains images from a variety of different hands, from different races, ages and genders, posed into Rock / Paper or Scissors and labelled as such. These images have all been generated using CGI techniques as an experiment in determining if a CGI-based dataset can be used for classification against real images. Rock Paper Scissors is a dataset containing 2,892 images of diverse hands in Rock/Paper/Scissors poses. There are 2520 images in the training set; and 372 images in the test set.

Note that all of this data is posed against a white background.
Each image is 300Ã—300 pixels in 24-bit color
